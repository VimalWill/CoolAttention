# CoolAttention 

Accelerator design to support "attention layers" in the modern transformer architecture. 

## TODO
1. Mixed Precision PEs
2. Approximated Activation func